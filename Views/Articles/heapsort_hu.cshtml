@section keywords {
    <meta name="keywords" content="heapsort, onlogn, binary heap, max min heap, heapify" />
}

@section topheading
{
    Heaposrt
}

@section subheading
{
    O(nlogn) sorting algorithm
}

@section description
{
    <article>
        <p>
            A heapsort algoritmust John William Joseph Williams találta fel
        </p>
        <p>
            A heapsort alghoritmusnak egy determinisztikus O(nlogn) időösszetettsége van, amellyel a 3 leggyrosabb rendezőalgoritmus egyike, azok között viszont a leglassabb, mivel a gyorsítótárat nem tudja kihasználni az egyre nagyobb tömbindexbeli ugrásai miatt.<br/>
            A másik 2 algoritmussal szemben ő nem használja az "oszd meg és uralkodj" elvet.<br/>
            Az algoritmus egyhelyben rendez, vagyis O(1) memóriaösszetettségű, de képes úgy kezelni ezt a tömböt mint egy minimum vagy maximum kupacot, és emiatt annyira gyors.<br/>
        </p>
        <p>
            Egy teljes bináris keresőf egy olyan fa, amelyben minden szint telített, és csak a legelacsonyabb szint lehet ez alól kivétel, Amelynek a baloldali része mindig telített.<br/>
            A pontok ebben a bináris fában pont olyan sorrendben vannak mint a betűk egy könyvben, ahogy olvasod őket.<br/>
            Mindössze itt nem sorokat olvasol, hanem szinteket.<br/>
            A elgfelsőbb pont indexe: 0 = (2^0 - 1), vagyis a bal közvetlen gyerekének pozíciója: 1, és a jobb közvetlené pedig 2.<br/>
            Eszerint, a legbalsóbb közvetlen gyereke a gyökérpontnak a balsó gyerekének: 3 (= 4 - 1), és annak a gyerekének a pozíciója pedig: 7 (= 8 - 1).<br/>
            Ez azért van, mert ha az n. szinten keresed a balszélső elem indexét, így számítanád ki:<br/>
            <br/>
            2^0 + 2^1 + 2^2 + 2^3 + ... + 2^(n-1) = a balszélső elem indexe az n. szinten<br/>
            <br/>
            Note: a pontok és a szintek indexelése is 0 alapú, azaz n = 0 az első szint<br/>
            <br/>
            A képlet végtére is csak összeadja az elemek számát az előző szinteken, ahhoz, hogy megkapjuk az első elem indexét az n. szinten.<br/>
            <br/>
            Ha mondjuk n = 1 (2-es szint), akkor index = 2^0 = 1, mert az első szinten csak 1 pont van.<br/>
            Ha mondjuk, n = 3 (level 4), akkor index = 2^0 + 2^1 + 2^2 = 7, mivel össze kell adjuk az 1-es, 2-es, 3-as szintek pontjainak a számát hogy megkapjuk 4-es szint első elemének indexét.<br/>
            <br/>
            Látszik, hogy a balszélső elemek indexei mindig 2-nek egyik hatvánayi minusz 1: 0, 1, 3, 7, 15, etc... Tudjuk bizonyítani?
        </p>
        <p>
            Egy AVL önkiegyensúlyozó keresőfa magaságának bizonyításához is ugyanerre van szükség.<br/>
            A bizonyítás azt mondja ki, hogy ha 2 szubszekvens hatványait adjuk össze, akkor ezen összeg plusz egy megint csak 2-nek egy hatványa.<br/>
            <br/>
            2^0 + 2^1 + 2^2 + 2^3 + 2^4 + ... + 2^(n-1) = x<br/>
            2^1 + 2^1 + 2^2 + 2^3 + 2^4 + ... + 2^(n-1) = x + 1<br/>
            2 * (2^1 + 2^1 + 2^2 + 2^3 + ... + 2^(n-2)) = x + 1<br/>
            2 * (2 * (2^1 + 2^1 + 2^2 + ... + 2^(n - 3))) = x + 1<br/>
            2^n = x + 1<br/>
            <br/>
            1 összegtagot mindig 1 faktorrá tudunk alakítani, és n darab ilyen tagunk van összesen.<br/>
            <br/>
            Vagyis 2^n-1 = x = a balszélső elem indexe az n. szinten
        </p>
        <p>
            Miért van erre szükség?<br/>
            Mert ezen algoritmusban csak arra lesz szükségünk, hogy tömbelem tömbindexéből megkaphassuk a bal közvetlen gyerekének a tömbbeli indexét konstans időben.<br/>
            Hogy csináljuk?<br/>
            <br/>
            2 dolgot tudunk:<br/>
            - The immediate child is on the one lower immediate level<br/>
            - The immediate left child is preceded by exactly 2 times the number of nodes left to its parent, because all of them have exactly 2 children on the 1 lower immediate level<br/>
            <br/>
            So let's say that we have a node at position p.<br/>
            We have an imaginary resolution for p:<br/>
            (2^n - 1) + x = p, and p < 2^(n + 1) - 1<br/>
            Where n is the index of the level on which the node resides.<br/>
            Where x is the zero-based index of node n, such that it is also the number of nodes left to it on the same level.
            <br/>
            In order to get to the left child node of a node, you will want to add up the number of nodes above it, and multiply the number of nodes left to its parent.<br/>
            And that is exactly the position of the parent node multiplied by 2, plus 1.<br/>
            <br/>
            Because p is the position of the parent, and<br/>
            2 * p = 2 * (2^n - 1) + 2 * x = 2 * ((2^n - 1) + x)<br/>
            2 * p = 2^(n+1) - 2 + 2x<br/>
            2 * p + 1 = 2(n+1) - 1 + 2x<br/>
            <br/>
            And that is the proof.<br/>
            Because 2^n - 1 is the position of the leftmost node of that level on which the parent node is, and therefore 2^(n+1) - 1 is the position of the leftmost node of the level just below it.<br/>
            And you need to add 2 times x more to that, because x is the number of nodes which precede the parent node, and since it is a complete binary tree whose leftmost part is always complete, 2 children per every node preceding the parent precede its left immediate child.<br/>
            <br/>
            And knowing that 2 * index + 1 equals the left immediate child of the node at a given index, plus 1 will equal the right immediate child.
        </p>
        <p>
            So where does heapsort use that formula?<br/>
            <br/>
            It has a recursive max_heapify() or min_heapify() function.<br/>
            A max_heapify() based heapsort produces a maximum heap, where both children of a node are smaller (or equal), and a min_heapify() based one produces a minimum heap, where the children of a node are both larger (or equal).<br/>
            <br/>
            So in case of a max/min heap, wherever you look, the root node of any subtree of a tree will be the largest/smallest element in that whole subtree.<br/>
            <br/>
            The heapify functions are able to heapify such a (sub)tree in which only the apex/top node is at wrong position in relation to other nodes of that (sub)tree.<br/>
            That essentially means, the 2 subtrees branching out of that node must be heapified/ must be already completely valid binary heaps.<br/>
            <br/>
            In that case, such a heapification takes at worst O(logn) time, where n is number of nodes that subtree, and logn is the height of the subtree.<br/>
            <br/>
            Because the height of any complete binary tree is always logn, because the number of nodes in a binary tree is a sum of incremental powers of 2, and such a sum plus 1 is also a power of 2.<br/>
            In terms of Big-O where constants are neglected, the plus 1 one is neglected, and it is fair enough.<br/>
            <br/>
            And so such a heapification takes O(logn) because what it does is just swapping nodes vertically, and never steps backwards, hence O(logn).<br/>
            <br/>
            On first occasion, you will need to perform heapification on every array element, starting from the nodes of the lowest level (minus 1 of course, because lowest level only consists of leaf nodes), so that you can heapify larger and larger subtrees based on the already heapified smaller subtrees on the lower level.<br/>
            <br/>
            This initial heapification will take you of course O(nlogn), since you are performing O(logn) operations for almost every node.<br/>
            <br/>
            Let's say you have the following tree with the following nodes:<br/>

            A                   (1)<br/>
            BC                  (2)<br/>
            DEFG                (4)<br/>
            HIJKLMNO            (8)<br/>
            PQRSTUVWXYZ01234    (16)<br/>
            <br/>
            First, you would heapify the subtrees HIJKLMNO, and you can do so, since by definition, their children are already heapified, since they are not real subtrees, they are all leaf nodes.<br/>
            Now you could then heapify subtrees DEFG because subtrees HIJKLMNO are already heapified.<br/>
            Then, you could heapify subtrees BC, because subtrees DEFG are already heapified.<br/>
            And finally, you could then heapify tree A, because subtrees BC are already heapified.
        </p>
        <p>
            So let's prove heapify functions actually work like that!<br/>
            1) We have an initial state:<br/>
            We have a subtree, and its 2 branches, and in both, the nodes inside are in correct relative position, meaning they are both independent, but are correct binary heaps on their own.<br/>
            <br/>
            2) Prove that, the change to this state produces another correct state, which is 1 correct binary heap with all elements being in correct position relative to each other!
        </p>
        <p>
            A single heapify call will restore a node and its 2 immediate children into correct relative position, meaning it will generate a correct local binary heap at that aggregate of nodes.<br/>
            If we have a maximum heap, it is determined which of the 3 elements is the largest.<br/>
            Given the largest element is one of the children nodes, it takes the top position and the other 2 are made to be the its children:<br/>
            <br/>
            Before:<br/>
            5<br/>
            47<br/>
            <br/>
            After:<br/>
            7<br/>
            45<br/>
            <br/>
            So yes, 1 heapify call indeed succeeds in creating a mini triangle which is a correct binary tree.<br/>
            It is said that, that largest element is bubbled up, while the smaller top element is bubbled down to take its place.
        </p>
        <p>
            A heapify can be safely performed on any binary tree, in which there is only 1 node which is in some incorrect position to some other nodes subordinate to it in the heap.<br/>
            First off, of course, this incorrect node is the apex of the subtree which we are looking at, but whenever it is bubbled down to a lower level, we get another binary heap in which all nodes except that node are in correct position relative to each other, and the bubbled down node may only be in incorrect position relative to its subordinates - so it is always in correct position relative to its superordinates inside that subtree - until that we will continue bubbling it down, until it either hits the end of the tree at which point it simply can not be any longer at incorrect position relative to subordinates, or until, the 1 subordinate is found to be in correct position relative to it, at which point all indirect subordinates must also be in correct position relative to it.
        </p>
        <p>
            1) Here, safe means on 1 hand, that bubbling up a node does not put that node into an incorrect position relative to any other (sub)tree nodes, if it was in correct position to all of them before, since its former immediate children are still subordinate to it, but now indirectly, and all its former indirectly superordinate nodes are still superordinate, the closest now being immediate parent to it.<br/>
            2) Safe means, on the other hand, bubbling down a node does not put that node into an incorrect position relative to its former superordinate nodes, which are still superordinate to it, though all of them indirectly.<br/>
            3) Safe also means all other nodes stayed at their place, therefore they are at correct positions relative to each other
            4) However, the bubbled down node can still be at incorrect position relative to its subordinate nodes
        </p>
        <p>
            That means, whenever we call heapification for the same node, it turns a subordinate which is in incorrect position relative to it into its immediate parent whcih must be at correct position now relative to it, and it is recursively applied up until:<br/>
            <br/>
            1) none of the new immediate children of the bubbled down node are in incorrect position relative to it, which of course also means none of its indirect children are at incorrect position relative to it<br/>
            2) it has no children, because we have arrived at the end of the tree, so it must be at correct position<br/>
            <br/>
            That means, this constantly bubbled down node eventually gets into correct position relative to all other elements in that subtree which we were looking that, so the change made to our initial state indeed produces another correct state.
        </p>
        <p>
            Since we are constantly bubbling down a node vertically, it is also proven that in worst case we are doing as many operations as tall the subtree was, which is O(logn) in worst case.<br/>
            <br/>
            So we can build a binary heap out of our input array in O(nlogn).<br/>
            <br/>
            Building a minimum heap is exactly the same story, but instread you are looking for smallest element out of the 3 and bubble that up, while bubbling the apex down to its place.
        </p>
        <p>
            But that is only half of the story.<br/>
            <br/>
            Now you are sure that the largest element of the array is the apex.<br/>
            That is the zeroth index of the array.<br/>
            It would be too easy to just put the resulting numbers into a new array.<br/>
            We are going to do it in place.<br/>
            You swap this apex with the element at the last array index, wich is the rightmost node on the lowest level.<br/>
            Now you heapify the tree at its apex again, to bubble down that small number you have just put there, but you specify a 1 smaller array length, so that heapify is not going to bother the largest number you have placed at the largest index.<br/>
            After heapification, you will have the largest node of the 1 smaller tree at the top position, but since this new tree was basically the largest plus all the rest, the largest of the rest is going to be the second largest.<br/>
            And again, you swap the apex with the node at the end of the last array index minus one, which is anyway the end of the 1 smaller heap we are considering in this second step.<br/>
            And you continue doing it, until you have an array with a length of at least 3 nodes.<br/>
        </p>
        <p>
            So this second part of heapsort will take you another O(nlogn) operations, and since you have O(nlogn) for first part, and O(nlogn) for second, you also have eventually O(nlogn).
        </p>
    </article>
}

@section btnname
{

}

@section url
{

}
